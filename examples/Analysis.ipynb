{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file allows to analyze results obtained by running experiments_paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "sys.path.append('../DeepSurvivalMachines/')\n",
    "from nsc import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to analyze other datasets result\n",
    "dataset = 'METABRIC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Results/' # Path where the data is saved\n",
    "x, t, e, covariates = datasets.load_dataset(dataset) # Open the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import concordance_index_ipcw, brier_score, cumulative_dynamic_auc, integrated_brier_score\n",
    "\n",
    "### Utils\n",
    "def evaluate(survival):\n",
    "    folds = survival.iloc[:, -1].values\n",
    "    survival = survival.iloc[:, :-1]\n",
    "    times = survival.columns.get_level_values(1).unique()\n",
    "    risk = 1 - survival\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # If multiple risk, compute cause specific metrics\n",
    "    for r in survival.columns.get_level_values(0).unique():\n",
    "        e_ = (e == int(r))\n",
    "        for fold in np.arange(5):\n",
    "            e_train, t_train = e_[folds != fold], t[folds != fold]\n",
    "            e_test,  t_test  = e_[folds == fold], t[folds == fold]\n",
    "\n",
    "            et_train = np.array([(e_train[i], t_train[i]) for i in range(len(e_train))],\n",
    "                            dtype = [('e', bool), ('t', float)])\n",
    "            et_test = np.array([(e_test[i], t_test[i]) for i in range(len(e_test))],\n",
    "                            dtype = [('e', bool), ('t', float)])\n",
    "            selection = (t_test < t_train.max()) | (e[folds == fold] == 0)\n",
    "            \n",
    "            et_test = et_test[selection]\n",
    "            survival_fold = survival[folds == fold][r][selection]\n",
    "            risk_fold = risk[folds == fold][r][selection]\n",
    "\n",
    "            brs = brier_score(et_train, et_test, survival_fold.values, times)[1]\n",
    "            # Concordance and ROC for each time\n",
    "            gcis, cis, rocs = [], [], []\n",
    "            for time in times:\n",
    "                gcis.append(concordance_index_ipcw(et_train, et_test, risk_fold[time])[0])\n",
    "                cis.append(concordance_index_ipcw(et_train, et_test, risk_fold[time], float(time))[0])\n",
    "                rocs.append(cumulative_dynamic_auc(et_train, et_test, risk_fold[time], float(time))[0][0])\n",
    "\n",
    "            results[(r, fold)] = pd.DataFrame.from_dict({\"GCIS\": gcis, \"CIS\": cis, \"BRS\": brs, \"ROCS\": rocs}, orient='index', columns = times)\n",
    "    results = pd.concat(results)\n",
    "    results.index.set_names(['Risk', 'Fold', 'Metric'], inplace = True)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file and compute performance\n",
    "predictions, clusters, results, likelihood = {}, {}, {}, {}\n",
    "for file_name in os.listdir(path):\n",
    "    if dataset in file_name and '.csv' in file_name: \n",
    "        model = file_name       \n",
    "        model = model[model.index('_') + 1: model.index('.')]\n",
    "\n",
    "        print(\"Opening :\", file_name, ' - ', model)\n",
    "        predictions[model] = pd.read_csv(path + file_name, header = [0, 1], index_col = 0)\n",
    "        results[model] = evaluate(predictions[model])\n",
    "\n",
    "        cluster_file = file_name[: file_name.index('.')] + '_clusters.pickle'\n",
    "        if os.path.isfile(path + cluster_file):\n",
    "            clusters[model] = pickle.load(open(path + cluster_file, 'rb'))\n",
    "# Rename\n",
    "# TODO: Add your method in the list for nicer display\n",
    "dict_name = {'nsc': 'NSC', 'cox': 'CoxPH', 'ds': 'DeepSurv', 'dsm': 'DSM', 'dcm': 'DCM', 'dh': 'DeepHit', 'rsf': 'RSF'} \n",
    "\n",
    "likelihood = pd.DataFrame.from_dict(likelihood, 'index').rename(dict_name)\n",
    "results = pd.concat(results).rename(dict_name)\n",
    "results.index.set_names('Model', 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = results.groupby(['Model', 'Risk', 'Metric']).apply(lambda x: pd.Series([\"{:.3f} ({:.2f})\".format(mean, std) for mean, std in zip(x.mean(), x.std())], index = x.columns.astype(float)))\n",
    "table = table.loc[table.index.get_level_values(2).isin(['CIS', 'BRS'])].unstack(level=-1).stack(level=0).unstack(level=-1).loc[:, ['CIS', 'BRS']]\n",
    "table = table.loc[['NSC', 'DCM', 'DSM', 'DeepHit', 'DeepSurv', 'CoxPH']]\n",
    "\n",
    "if len(table.index.get_level_values(1).unique()) == 1:\n",
    "    table = table.droplevel(1)\n",
    "else:\n",
    "    table = table.reorder_levels(['Risk', 'Model']).sort_index(level = 0, sort_remaining = False)\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anlayze the outcome of the method\n",
    "method_display = 'nsc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(5):\n",
    "    print(i)\n",
    "    horizons_pred = np.linspace(0, 0.75, 10)\n",
    "    if 'predictions' not in clusters[method_display][i]:\n",
    "        for risk in clusters[method_display][i]:\n",
    "            pd.DataFrame(clusters[method_display][i][risk]['predictions'], index = np.quantile(t[e!= 0], horizons_pred)).plot()\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel('Survival Predictions')\n",
    "            plt.grid(alpha = 0.3)\n",
    "            plt.legend(title = 'Clusters - Risk {}'.format(risk))\n",
    "            plt.show()\n",
    "    else:\n",
    "        pd.DataFrame(clusters[method_display][i]['predictions'], index = np.quantile(t[e==1], horizons_pred)).plot()\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Survival Predictions')\n",
    "        plt.grid(alpha = 0.3)\n",
    "        plt.legend(title = 'Clusters')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import multivariate_logrank_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average life expectancy for each cluster\n",
    "clusters_expectancy, clusters_assignments = [], []\n",
    "for fold in clusters[method_display]:\n",
    "    index = clusters[method_display][fold]['alphas_test'].index\n",
    "    order = np.argsort(clusters[method_display][fold]['predictions'][-1]) # Reorder cluster\n",
    "    clusters_assignment = np.argmax(clusters[method_display][fold]['alphas_test'].iloc[:, order].values, axis = 1)\n",
    "    clusters_assignment = pd.DataFrame({'Assignment': clusters_assignment, 'Event': e[index], 'Time': t[index]}, index = index)\n",
    "    clusters_assignments.append(clusters_assignment)\n",
    "    clusters_expectancy.append(clusters_assignment.groupby('Assignment').apply(lambda x: KaplanMeierFitter().fit(x['Time'], x['Event']).median_survival_time_))\n",
    "    print(multivariate_logrank_test(clusters_assignment['Time'], clusters_assignment['Assignment'], clusters_assignment['Event']))\n",
    "clusters_assignments = pd.concat(clusters_assignments, 0)\n",
    "clusters_expectancy = pd.concat(clusters_expectancy, 1).replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Survival\")\n",
    "clusters_expectancy.mean(1), clusters_expectancy.std(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Characteristics Clusters\")\n",
    "pd.concat([pd.DataFrame(x, columns = covariates), clusters_assignments], axis = 1).groupby('Assignment').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage Population\")\n",
    "clusters_assignments.groupby('Assignment').size() * 100 / len(clusters_assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Censored\")\n",
    "(1 - clusters_assignments.groupby('Assignment').mean()['Event']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Difference in Survival\")\n",
    "multivariate_logrank_test(clusters_assignments['Time'], clusters_assignments['Assignment'], clusters_assignments['Event']).summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display importance of features obtained by test\n",
    "importance = []\n",
    "for j in clusters[method_display]:\n",
    "    importance.append(pd.Series(clusters[method_display][j]['importance'][0]))\n",
    "\n",
    "importance = - pd.concat(importance, axis = 1)\n",
    "importance.index = covariates\n",
    "importance.mean(1).sort_values().plot.bar(yerr = importance.std(1))\n",
    "plt.xlabel('Covariate')\n",
    "plt.ylabel('Likelihood change')\n",
    "plt.grid(alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in clusters[method_display]:\n",
    "    tsne = TSNE(n_components = 2, random_state=0)\n",
    "    tsne = pd.DataFrame(tsne.fit_transform(clusters[method_display][i]['alphas_train']), columns = ['Projection 1', 'Projection 2'], index = clusters[method_display][i]['alphas_train'].index)\n",
    "    tsne['Survival time'] = (t[tsne.index]) #np.digitize(t[tsne.index], [0,100,200,400])\n",
    "    tsne.plot.scatter('Projection 1', 'Projection 2', c = 'Survival time', cmap='viridis', alpha = 0.5)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a54f3b3a447186e9a4a83057d2abe8df010acd7b8f131225203d307ef84eba48"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('Jupyter': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
